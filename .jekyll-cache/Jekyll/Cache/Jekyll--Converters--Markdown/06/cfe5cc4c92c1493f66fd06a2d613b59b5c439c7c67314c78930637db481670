I"è/<!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SOCC</abbr></div>

        <!-- Entry bib key -->
        <div id="9524757" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A DNN Compression Framework for SOT-MRAM-based Processing-In-Memory Engine</div>
          <!-- Author -->
          <div class="author">Yuan, Geng,&nbsp;Ma, Xiaolong,&nbsp;Lin, Sheng,&nbsp;Li, Zhengang,&nbsp;Deng, Jieren,&nbsp;and Ding, Caiwen
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 2020 IEEE 33rd International System-on-Chip Conference (SOCC)</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS SpicyFL</abbr></div>

        <!-- Entry bib key -->
        <div id="https://doi.org/10.48550/arxiv.2009.01867" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">ESMFL: Efficient and Secure Models for Federated Learning</div>
          <!-- Author -->
          <div class="author">Lin, Sheng,&nbsp;Wang, Chenghong,&nbsp;Li, Hongjia,&nbsp;Deng, Jieren,&nbsp;Wang, Yanzhi,&nbsp;and Ding, Caiwen
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="https://doi.org/10.48550/arxiv.2009.06228" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">SAPAG: A Self-Adaptive Privacy Attack From Gradients</div>
          <!-- Author -->
          <div class="author">Wang, Yijue,&nbsp;Deng, Jieren,&nbsp;Guo, Dan,&nbsp;Wang, Chenghong,&nbsp;Meng, Xianrui,&nbsp;Liu, Hang,&nbsp;Ding, Caiwen,&nbsp;and Rajasekaran, Sanguthevar
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICCAD</abbr></div>

        <!-- Entry bib key -->
        <div id="9643440" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">FL-DISCO: Federated Generative Adversarial Network for Graph-based Molecule Drug Discovery: Special Session Paper</div>
          <!-- Author -->
          <div class="author">Manu, Daniel,&nbsp;Sheng, Yi,&nbsp;Yang, Junhuan,&nbsp;Deng, Jieren,&nbsp;Geng, Tong,&nbsp;Li, Ang,&nbsp;Ding, Caiwen,&nbsp;Jiang, Weiwen,&nbsp;and Yang, Lei
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">DATE</abbr></div>

        <!-- Entry bib key -->
        <div id="9474235" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">TinyADC: Peripheral Circuit-aware Weight Pruning Framework for Mixed-signal DNN Accelerators</div>
          <!-- Author -->
          <div class="author">Yuan, Geng,&nbsp;Behnam, Payman,&nbsp;Cai, Yuxuan,&nbsp;Shafiee, Ali,&nbsp;Fu, Jingyan,&nbsp;Liao, Zhiheng,&nbsp;Li, Zhengang,&nbsp;Ma, Xiaolong,&nbsp;Deng, Jieren,&nbsp;Wang, Jinhui,&nbsp;Bojnordi, Mahdi,&nbsp;Wang, Yanzhi,&nbsp;and Ding, Caiwen
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 2021 Design, Automation   Test in Europe Conference   Exhibition (DATE)</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">BIB</abbr></div>

        <!-- Entry bib key -->
        <div id="wu2021novel" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A novel privacy-preserving federated genome-wide association study framework and its application in identifying potential risk variants in ankylosing spondylitis</div>
          <!-- Author -->
          <div class="author">Wu, Xin,&nbsp;Zheng, Hao,&nbsp;Dou, Zuochao,&nbsp;Chen, Feng,&nbsp;Deng, Jieren,&nbsp;Chen, Xiang,&nbsp;Xu, Shengqian,&nbsp;Gao, Guanmin,&nbsp;Li, Mengmeng,&nbsp;Wang, Zhen,&nbsp;and others, 
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Briefings in Bioinformatics</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://academic.oup.com/bib/article/22/3/bbaa090/5860679?login=true" class="btn btn-sm z-depth-0" role="button">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Genome-wide association studies (GWAS) have been widely used for identifying potential risk variants in various diseases. A statistically meaningful GWAS typically requires a large sample size to detect disease-associated single nucleotide polymorphisms (SNPs). However, a single institution usually only possesses a limited number of samples. Therefore, cross-institutional partnerships are required to increase sample size and statistical power. However, cross-institutional partnerships offer significant challenges, a major one being data privacy. For example, the privacy awareness of people, the impact of data privacy leakages and the privacy-related risks are becoming increasingly important, while there is no de-identification standard available to safeguard genomic data sharing. In this paper, we introduce a novel privacy-preserving federated GWAS framework (iPRIVATES). Equipped with privacy-preserving federated analysis, iPRIVATES enables multiple institutions to jointly perform GWAS analysis without leaking patient-level genotyping data. Only aggregated local statistics are exchanged within the study network. In addition, we evaluate the performance of iPRIVATES through both simulated data and a real-world application for identifying potential risk variants in ankylosing spondylitis (AS). The experimental results showed that the strongest signal of AS-associated SNPs reside mostly around the human leukocyte antigen (HLA) regions. The proposed iPRIVATES framework achieved equivalent results as traditional centralized implementation, demonstrating its great potential in driving collaborative genomic research for different diseases while preserving data privacy.</p>
          </div>
        </div>
      </div>
</li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div>

        <!-- Entry bib key -->
        <div id="deng-etal-2021-tag-gradient" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">TAG: Gradient Attack on Transformer-based Language Models</div>
          <!-- Author -->
          <div class="author">Deng, Jieren,&nbsp;Wang, Yijue,&nbsp;Li, Ji,&nbsp;Wang, Chenghong,&nbsp;Shang, Chao,&nbsp;Liu, Hang,&nbsp;Rajasekaran, Sanguthevar,&nbsp;and Ding, Caiwen
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Findings of the Association for Computational Linguistics: EMNLP 2021</em> Nov 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://aclanthology.org/2021.findings-emnlp.305.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Although distributed learning has increasingly gained attention in terms of effectively utilizing local devices for data privacy enhancement, recent studies show that publicly shared gradients in the training process can reveal the private training data (gradient leakage) to a third-party. We have, however, no systematic understanding of the gradient leakage mechanism on the Transformer based language models. In this paper, as the first attempt, we formulate the gradient attack problem on the Transformer-based language models and propose a gradient attack algorithm, TAG, to reconstruct the local training data. Experimental results on Transformer, TinyBERT4, TinyBERT6 BERT_BASE, and BERT_LARGE using GLUE benchmark show that compared with DLG, TAG works well on more weight distributions in reconstructing training data and achieves 1.5x recover rate and 2.5x ROUGE-2 over prior methods without the need of ground truth label. TAG can obtain up to 90% data by attacking gradients in CoLA dataset. In addition, TAG is stronger than previous approaches on larger models, smaller dictionary size, and smaller input length. We hope the proposed TAG will shed some light on the privacy leakage problem in Transformer-based NLP models.</p>
          </div>
        </div>
      </div>
</li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div>

        <!-- Entry bib key -->
        <div id="wang-etal-2021-secure" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Secure and Efficient Federated Learning Framework for NLP</div>
          <!-- Author -->
          <div class="author">Deng, Jieren,&nbsp;Wang, Chenghong,&nbsp;Meng, Xianrui,&nbsp;Wang, Yijue,&nbsp;Li, Ji,&nbsp;Lin, Sheng,&nbsp;Han, Shuo,&nbsp;Miao, Fei,&nbsp;Rajasekaran, Sanguthevar,&nbsp;and Ding, Caiwen
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em> Nov 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://aclanthology.org/2021.emnlp-main.606.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this work, we consider the problem of designing secure and efficient federated learning (FL) frameworks for NLP. Existing solutions under this literature either consider a trusted aggregator or require heavy-weight cryptographic primitives, which makes the performance significantly degraded. Moreover, many existing secure FL designs work only under the restrictive assumption that none of the clients can be dropped out from the training protocol. To tackle these problems, we propose SEFL, a secure and efficient federated learning framework that (1) eliminates the need for the trusted entities; (2) achieves similar and even better model accuracy compared with existing FL designs; (3) is resilient to client dropouts.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"></ol>


</div>
:ET